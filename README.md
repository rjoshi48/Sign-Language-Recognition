# Sign-Language-Recognition
The project focuses on recognizing the hand gestures, which can then be used to interpret sign language. A sign language is made up of a clearly defined code of signs and gestures, each of which has a specific meaning. It consists of a combination of hand positioning, shapes, and movements. Deaf and mute people typically communicate through sign language interpreters. But finding a good interpreter can be challenging and often costlier. A machine learning model could be a more dependable and less expensive solution to this problem.

To solve this problem the following metholody is adopted:

![Methodology](https://github.com/rjoshi48/Sign-Language-Recognition/assets/114186247/97d53b74-1d4c-4448-9ae5-eb2107b2b6a9)
